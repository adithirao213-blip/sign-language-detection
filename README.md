This project focuses on recognizing hand gestures and converting them into text using Sign Language Detection. It leverages computer vision and machine learning to help bridge the communication gap between hearing-impaired individuals and others.

Features:
1.Real-time hand gesture recognition.
2.Detection of commonly used sign language alphabets/words.
3.Converts signs into readable text (and can be extended to speech).
4.Easy-to-use interface.

Programming Language: Python
Libraries/Frameworks: OpenCV, TensorFlow/Keras, NumPy, Mediapipe
